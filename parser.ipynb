{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63baf5fb-2304-4d6d-b78c-b0e1bcad5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсинг объявления с ID: 697967365 завершен. Обработано строк: 2003\n",
      "Парсинг завершен. Данные сохранены в krisha_arenda_data.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Базовый URL страницы с квартирами\n",
    "base_url = 'https://krisha.kz/arenda/kvartiry/almaty/?page='\n",
    "\n",
    "# Количество страниц для парсинга\n",
    "pages_to_scrape = 100\n",
    "\n",
    "# Имя файла Excel\n",
    "excel_file = 'krisha_arenda_data.xlsx'\n",
    "\n",
    "# Создаем новый Excel файл, если его нет\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "# Добавляем заголовки\n",
    "columns = [\n",
    "    'ID', 'Title', 'Address', 'User Type', 'Square', 'Rooms', 'Status', 'Latitude', 'Longitude', \n",
    "    'Price per m²', 'Created At', 'Owner Title', 'Owner Label Title', 'Owner Label Name', \n",
    "    'Year of Construction', 'Condition', 'Floor', 'Number of Photos', 'Category Alias', 'District', 'Country', 'City', 'Price'\n",
    "]\n",
    "ws.append(columns)\n",
    "wb.save(excel_file)\n",
    "\n",
    "# Функция для извлечения JSON-данных из JavaScript на странице объявления\n",
    "def extract_data_from_script(soup):\n",
    "    script = soup.find('script', string=lambda t: t and 'window.data' in t)\n",
    "    \n",
    "    if script:\n",
    "        script_content = script.string.strip()\n",
    "        json_data_start = script_content.find('{')\n",
    "        json_data_end = script_content.rfind('}') + 1\n",
    "        try:\n",
    "            data = json.loads(script_content[json_data_start:json_data_end])\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Ошибка при декодировании JSON.\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Функция для парсинга детализированной страницы объявления\n",
    "def parse_detailed_page(data_id):\n",
    "    detailed_url = f'https://krisha.kz/a/show/{data_id}'\n",
    "    response = requests.get(detailed_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Извлекаем данные из JavaScript\n",
    "    data = extract_data_from_script(soup)\n",
    "\n",
    "    if data:\n",
    "        advert = data.get('advert', {})\n",
    "        # Данные с adverts, так как в них могут быть важные данные\n",
    "        adverts_list = data.get('adverts', [])\n",
    "\n",
    "        # Извлекаем нужные данные из advert\n",
    "        advert_id = advert.get('id', 'N/A')\n",
    "        title = advert.get('title', 'N/A')\n",
    "        address = advert.get('addressTitle', 'N/A')\n",
    "        user_type = advert.get('userType', 'N/A')\n",
    "        square = advert.get('square', 'N/A')\n",
    "        rooms = advert.get('rooms', 'N/A')\n",
    "        status = advert.get('status', 'N/A')\n",
    "        lat = advert.get('map', {}).get('lat', 'N/A')\n",
    "        lon = advert.get('map', {}).get('lon', 'N/A')\n",
    "        price = advert.get('price', 'N/A')\n",
    "        district = advert.get('address', {}).get('district', 'N/A')\n",
    "        country = advert.get('address', {}).get('country', 'N/A')\n",
    "        city = advert.get('address', {}).get('city', 'N/A')\n",
    "\n",
    "        # Дополнительные данные из adverts\n",
    "        if adverts_list:\n",
    "            price_m2 = adverts_list[0].get('priceM2', 'N/A')\n",
    "            created_at = adverts_list[0].get('createdAt', 'N/A')\n",
    "            owner_data = adverts_list[0].get('owner', {})\n",
    "            owner_title = owner_data.get('title', 'N/A')\n",
    "            owner_label_title = owner_data.get('label', {}).get('title', 'N/A')\n",
    "            owner_label_name = owner_data.get('label', {}).get('name', 'N/A')\n",
    "            num_photos = adverts_list[0].get('nbPhotos', 'N/A')\n",
    "            category_alias = adverts_list[0].get('category', {}).get('label', 'N/A')\n",
    "        else:\n",
    "            price_m2 = 'N/A'\n",
    "            created_at = 'N/A'\n",
    "            owner_title = 'N/A'\n",
    "            owner_label_title = 'N/A'\n",
    "            owner_label_name = 'N/A'\n",
    "            num_photos = 'N/A'\n",
    "            category_alias = 'N/A'\n",
    "\n",
    "        # Парсим данные о годе постройки, этаже и состоянии\n",
    "        construction_year = 'N/A'\n",
    "        condition = 'N/A'\n",
    "        floor = 'N/A'\n",
    "\n",
    "        # Ищем соответствующие теги с нужной информацией\n",
    "        for item in soup.find_all('div', class_='offer__info-item'):\n",
    "            data_name = item.get('data-name', '')\n",
    "            if data_name == 'house.year':\n",
    "                construction_year = item.find('div', class_='offer__advert-short-info').text.strip()\n",
    "            elif data_name == 'flat.floor':\n",
    "                floor = item.find('div', class_='offer__advert-short-info').text.strip()\n",
    "            elif data_name == 'flat.renovation':\n",
    "                condition = item.find('div', class_='offer__advert-short-info').text.strip()\n",
    "\n",
    "        # Сохраняем данные поочередно в Excel\n",
    "        wb = load_workbook(excel_file)\n",
    "        ws = wb.active\n",
    "        row = [\n",
    "            advert_id, title, address, user_type, square, rooms, status, lat, lon, \n",
    "            price_m2, created_at, owner_title, owner_label_title, owner_label_name, \n",
    "            construction_year, condition, floor, num_photos, category_alias, district, country, city, price\n",
    "        ]\n",
    "        ws.append(row)\n",
    "        wb.save(excel_file)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Счетчик строк\n",
    "rows_processed = 0\n",
    "\n",
    "# Проход по каждой странице списка объявлений\n",
    "for page in range(1, pages_to_scrape + 1):\n",
    "    url = base_url + str(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Проход по каждому объявлению и извлечение data-id\n",
    "    for listing in soup.find_all('div', class_='a-card'):\n",
    "        data_id = listing.get('data-id')\n",
    "        if data_id:\n",
    "            success = parse_detailed_page(data_id)\n",
    "            if success:\n",
    "                rows_processed += 1\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Парсинг объявления с ID: {data_id} завершен. Обработано строк: {rows_processed}\")\n",
    "                time.sleep(1)  # Пауза для уменьшения нагрузки на сервер\n",
    "\n",
    "print(f\"Парсинг завершен. Данные сохранены в {excel_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca544ed3-7712-4115-b73e-866e543d5250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c9e65-4782-4eb4-a61a-d56fdfdfe6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
